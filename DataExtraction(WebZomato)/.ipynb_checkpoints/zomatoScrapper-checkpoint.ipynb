{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Pulls details of banglore restaurants Zomato pagewise to and saves it to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "startUrl = \"https://www.zomato.com/bangalore/restaurants\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used headers/agent because the request was timed out and asking for an agent. \n",
    "#Using following code we can fake the agent.\n",
    "\n",
    "def getSoup(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}\n",
    "    response = requests.get(url,headers=headers)\n",
    "    \n",
    "    content = response.content\n",
    "    soup = BeautifulSoup(content,\"html.parser\")\n",
    "    print(url)\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max pages\n",
    "def getMaxPages():\n",
    "    soup = getSoup(startUrl)\n",
    "    pages = []\n",
    "    pagesTag = soup.find(\"div\",attrs={\"class\":\"col-l-4 mtop pagination-number\"})\n",
    "    pagesTag_temp = pagesTag.find_all(\"b\",recursive=True)\n",
    "    \n",
    "    for p in pagesTag_temp:\n",
    "        pages.append(p.get_text())\n",
    "        \n",
    "    return int(max(pages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.zomato.com/bangalore/restaurants\n",
      "900\n",
      "https://www.zomato.com/bangalore/restaurants?page=2\n",
      "https://www.zomato.com/bangalore/hyderabad-biryaani-house-richmond-road-bangalore\n",
      "https://www.zomato.com/bangalore/hyderabad-biryaani-house-richmond-road-bangalore\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-60b380c050b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#restaurant title\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtop_header_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"h1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"ui res-name mb0 header nowrap\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"restaurant_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_header_title\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"restaurant_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "\n",
    "list_dataframes = []\n",
    "currentpage = 2\n",
    "maxPages = getMaxPages()\n",
    "# print(maxPages)\n",
    "while currentpage <= maxPages:\n",
    "    \n",
    "    pageUrl = startUrl+\"?page=\"+str(currentpage)\n",
    "    soup = getSoup(pageUrl)\n",
    "    list_rest = soup.find_all(\"div\",attrs={\"class\": \"col-s-12\"})\n",
    "    \n",
    "    for rest in list_rest:\n",
    "        dataframe = OrderedDict() #dict\n",
    "\n",
    "        #restaurant link\n",
    "        link = rest.find(\"a\",attrs={\"class\": \"result-title hover_feedback zred bold ln24 fontsize0\"})\n",
    "        dataframe[\"restaurant_link\"] = link['href']\n",
    "        \n",
    "        print(dataframe[\"restaurant_link\"])\n",
    "        soup = getSoup(link['href'])\n",
    "        \n",
    "        #Res Id\n",
    "        res_id = soup.find(\"head\")\n",
    "        scripts = res_id.select('script')\n",
    "        for script in scripts:\n",
    "            if 'window.RES_ID' in script.text:\n",
    "                ids = re.findall('\\d+', script.contents[0])\n",
    "                dataframe[\"restaurant_ID\"] = ids[0]\n",
    "        \n",
    "        #restaurant title\n",
    "        top_header_title = (soup.find(\"h1\",attrs={\"class\":\"ui res-name mb0 header nowrap\"}))\n",
    "        dataframe[\"restaurant_name\"] = top_header_title.find(\"a\").get_text().strip()\n",
    "\n",
    "        print(dataframe[\"restaurant_name\"])  \n",
    "    \n",
    "        #locality\n",
    "        loc_title = (soup.find(\"div\",attrs={\"class\":\"mb5 pt5 clear\"}))\n",
    "        dataframe[\"locality\"] = loc_title.find(\"a\").get_text().strip()\n",
    "\n",
    "        #category\n",
    "        res_category_tag = loc_title.find(\"span\",attrs={\"class\":\"res-info-estabs grey-text fontsize3\"})\n",
    "        if res_category_tag is not None:\n",
    "            res_category = res_category_tag.find(\"a\")\n",
    "            if res_category is not None:\n",
    "                dataframe[\"restaurant_category\"] = res_category_tag.find(\"a\").get_text().strip()\n",
    "            else:\n",
    "                dataframe[\"restaurant_category\"] = res_category_tag.get_text().strip()#Delivery\n",
    "        \n",
    "        #zomato gold\n",
    "        goldTag = soup.find(\"div\",attrs={\"class\":\"red_res_tag\"})\n",
    "        if goldTag is not None:\n",
    "            goldTag_temp = goldTag.find(\"img\")\n",
    "            if goldTag_temp is not None:\n",
    "                dataframe[\"zomato_gold\"] = \"zomato gold\"\n",
    "            else:\n",
    "                dataframe[\"zomato_gold\"] = \"NA\"\n",
    "        else:\n",
    "            dataframe[\"zomato_gold\"] = \"NA\"\n",
    "\n",
    "        #discounts\n",
    "        discountTag = soup.find(\"div\",attrs={\"class\": \"fontsize flex flex-center-v\"})\n",
    "        if discountTag is not None:\n",
    "            discountTag_temp = discountTag.find(\"div\",attrs={\"class\":\"pr5\"})\n",
    "            if discountTag_temp is not None:\n",
    "                dataframe[\"discounts\"] = discountTag_temp.getText().strip()\n",
    "            else:\n",
    "                dataframe[\"discounts\"] = \"NA\"\n",
    "        else:\n",
    "            dataframe[\"discounts\"] = \"NA\"\n",
    "        \n",
    "        #photos\n",
    "        photosTag = soup.find_all(\"div\",attrs={\"respageMenuContainer\"})\n",
    "        for photo in photosTag:\n",
    "            children = photo.findChildren(\"a\",attrs={\"item respageMenu-item photosTab restaurant-tab-item-jumbo-track\"})\n",
    "            for child in children:\n",
    "                reObj = re.compile('\\d+')\n",
    "                dataframe[\"photos_taken\"] = reObj.findall(child.text.strip())[0]\n",
    "\n",
    "        #rating\n",
    "        top_header_rating = (soup.find(\"div\",attrs={\"class\":\"col-l-4 tac left\"}))\n",
    "        rating = top_header_rating.find(\"div\",attrs={\"class\":\"rating_hover_popup res-rating pos-relative clearfix mb5\"})\n",
    "\n",
    "        if rating is not None:\n",
    "            r = rating.get_text().replace('\\n',' ').strip()\n",
    "            ratingList = r.split('/')\n",
    "            dataframe[\"rating\"] = ratingList[0].strip()\n",
    "        else:\n",
    "            dataframe[\"rating\"] = \"NA\"\n",
    "        \n",
    "        print(dataframe[\"rating\"])\n",
    "\n",
    "        #votes\n",
    "        top_header_votes = top_header_rating.find(\"span\",attrs={\"class\":\"mt2 mb0 rating-votes-div rrw-votes grey-text fontsize5 ta-right\"})\n",
    "        if top_header_votes is not None:\n",
    "            reObj = re.compile('\\d+')\n",
    "            dataframe[\"votes\"] = reObj.findall(top_header_votes.get_text())[0]\n",
    "        else:\n",
    "            dataframe[\"votes\"] = \"NA\"\n",
    "\n",
    "        #cuisines\n",
    "        info_left = (soup.find(\"div\",attrs={\"class\":\"col-l-1by3 pl0 pr20\"}))\n",
    "        cuisine_info = info_left.find(\"div\",attrs={\"class\":\"res-info-cuisines clearfix\"})\n",
    "        dataframe[\"cuisines\"] = cuisine_info.get_text()\n",
    "\n",
    "        #Approx cost\n",
    "        approxCost_tag = info_left.find(\"div\",attrs={\"class\":\"res-info-detail\"})\n",
    "        if approxCost_tag is not None:\n",
    "            approx_cost = approxCost_tag.find(\"span\",attrs={\"tabindex\":\"0\"})\n",
    "        if approx_cost is not None:\n",
    "            reObj = re.compile('\\d+')\n",
    "            dataframe[\"approx_cost_for_2\"] = reObj.findall(approx_cost.get_text().replace(',','').strip())[0]\n",
    "        else:\n",
    "            dataframe[\"approx_cost_for_2\"] = \"NA\"\n",
    "        \n",
    "        #Opening timings\n",
    "        info_centre = (soup.find(\"div\",attrs={\"class\":\"col-l-1by3 pl20 pr20\"}))\n",
    "        if info_centre is not None:\n",
    "            openingtimes = info_centre.find(\"div\",attrs={\"class\":\"res-info-timings\"})\n",
    "            if openingtimes is not None:\n",
    "                timings = openingtimes.find(\"div\",attrs={\"class\":\"medium\"})\n",
    "                dataframe[\"opening_timings\"] = re.findall(r'\\s(\\d*\\:\\d*\\s?(?:AM|PM|am|pm|noon|midnight|Hours|hours)|\\d*\\s?(?:AM|PM|am|pm|noon|midnight|Hours|hours))',timings.get_text())\n",
    "            else:\n",
    "                dataframe[\"opening_timings\"] = \"NA\"\n",
    "        \n",
    "        #address\n",
    "        addressTag = info_centre.find(\"div\",attrs={\"class\":\"mbot0\"})\n",
    "        address = addressTag.find(\"span\")\n",
    "        if addressTag and address is not None:\n",
    "            dataframe[\"address\"] = address.get_text()\n",
    "        else:\n",
    "            dataframe[\"address\"] = \"NA\"\n",
    "        \n",
    "        #lat-long\n",
    "        lat_longTag = soup.find(\"div\",attrs={\"class\":\"resmap pos-relative mt5 mb5\"})\n",
    "        if lat_longTag is not None:\n",
    "            lat_long_scripts = lat_longTag.select('script')\n",
    "            for script in lat_long_scripts:\n",
    "                reObj = re.compile('\\d*\\.\\d*')\n",
    "                lat_lon = reObj.findall(script.contents[0])\n",
    "                \n",
    "                if lat_lon is not None:\n",
    "                    dataframe[\"latitude\"] = lat_lon[0]\n",
    "                    dataframe[\"longitude\"] = lat_lon[1]\n",
    "                else:\n",
    "                    dataframe[\"longitude\"] = dataframe[\"latitude\"] = \"NA\"\n",
    "\n",
    "        #more info\n",
    "        more_info = (soup.find_all(\"div\",attrs={\"class\":\"res-info-highlights\"}))\n",
    "        if more_info == []:\n",
    "            dataframe[\"more_info\"] = \"NA\"\n",
    "        else:\n",
    "            for child in more_info:\n",
    "                infos = child.find_all(\"div\",attrs={\"class\":\"res-info-feature-text\"})\n",
    "                infostring = []\n",
    "                for info in infos:\n",
    "                    infostring.append(info.get_text())\n",
    "                dataframe[\"more_info\"] = infostring\n",
    "            \n",
    "        #Featured in Collections\n",
    "        featured_in_tag = soup.find(\"div\",attrs={\"class\":\"mbot0 ptop0\"})\n",
    "        if featured_in_tag is not None:\n",
    "            featured_in = featured_in_tag.find(\"div\",attrs={\"class\":\"resbox__main--row res-info-group clearfix\"})\n",
    "\n",
    "            if featured_in is not None:\n",
    "                features = featured_in.find_all(\"a\")\n",
    "            if features is not None: \n",
    "                dataframe[\"featured_in\"] = [ftr.get_text().replace('\\ ',' ').strip() for ftr in features]\n",
    "                print(dataframe[\"featured_in\"])\n",
    "            else:\n",
    "                dataframe[\"featured_in\"] = \"NA\"\n",
    "        else:\n",
    "            dataframe[\"featured_in\"] = \"NA\"\n",
    "            \n",
    "            \n",
    "        #known for\n",
    "        knownForTag = soup.find_all(\"div\",attrs={\"class\":\"mbot0 ptop0\"})\n",
    "        if knownForTag == []:\n",
    "            dataframe[\"known_for\"] = \"NA\"\n",
    "        else:\n",
    "            for child in knownForTag:\n",
    "                known_for_list = child.find_all(\"div\",attrs={\"class\":\"res-info-known-for-text mr5\"})\n",
    "                for known_for in known_for_list:\n",
    "                    dataframe[\"known_for\"] = known_for.get_text().strip()            \n",
    "\n",
    "        #loved here food\n",
    "        mostlovedTags = soup.find_all(\"div\",attrs={\"class\":\"rv_highlights__wrapper mtop0\"})\n",
    "        j = []\n",
    "        for child in mostlovedTags:\n",
    "            j = child.find_all(\"div\",attrs={\"class\":\"rv_highlights__section pr10\"})\n",
    "        \n",
    "        if j == []:\n",
    "            dataframe[\"most_liked_Food\"] = \"NA\"\n",
    "            dataframe[\"most_liked_Service\"] = \"NA\"\n",
    "            dataframe[\"most_liked_Look & Feel\"] = \"NA\"\n",
    "        else:    \n",
    "            for op in j:\n",
    "                mostlovedcategory = op.find(\"div\",attrs={\"class\":\"grey-text\"})\n",
    "\n",
    "                loved_here = op.find(\"div\",attrs={\"class\":\"rv_highlights__score_bar mt5 mb5\"})\n",
    "                blockbg = loved_here.find_all(\"div\",attrs={\"class\":\"block bd-txt-bg\"})\n",
    "\n",
    "                mostLoved = op.find(\"div\",attrs={\"class\":\"fontsize13 ln18\"})\n",
    "                if mostLoved is not None:\n",
    "                    item = mostLoved.find_all(\"span\")\n",
    "                    if item is not None:\n",
    "                        temp = []\n",
    "                        temp.append(str(5-len(blockbg))+\"/5\")\n",
    "                        for i in item:\n",
    "                            temp.append(i.get_text().replace(',','').strip())\n",
    "                        dataframe[\"most_liked_\"+mostlovedcategory.get_text()] = temp\n",
    "\n",
    "        ##reviews\n",
    "        review_link = link['href']+\"/reviews\"\n",
    "        review_soup = getSoup(review_link)\n",
    "\n",
    "        review_header = (review_soup.find_all(\"div\",attrs={\"class\":\"res-reviews-container res-reviews-area\"}))\n",
    "        review_list = []\n",
    "        for i in review_header:\n",
    "            main = []\n",
    "            rev_details_parent = i.findChildren(\"div\",attrs={'fs12px pbot0 clearfix'})\n",
    "            for j in rev_details_parent:\n",
    "                rev_info = []\n",
    "                rev_info.append(j.time['datetime'])\n",
    "                if j.find(\"div\",attrs={\"class\":\"positive-sentiment\"}):\n",
    "                    rev_info.append(\"positive\")\n",
    "                else:\n",
    "                    rev_info.append(\"NA\")\n",
    "                    \n",
    "                if j.find(\"div\",attrs={\"class\":\"negative-sentiment\"}):\n",
    "                    rev_info.append(\"negative\")\n",
    "                else:\n",
    "                    rev_info.append(\"NA\")\n",
    "                    \n",
    "                main.append(rev_info)\n",
    "            \n",
    "            rev_children = i.findChildren(\"div\",attrs={\"rev-text mbot0\",\"rev-text-sm mbot0\"})\n",
    "            \n",
    "            for indx,child in enumerate(rev_children):\n",
    "                reviewtxt = child.text.replace('Rated\\xa0\\n','').strip()\n",
    "                main[indx].append(reviewtxt.replace('\\n',''))\n",
    "                \n",
    "        dataframe[\"reviews\"] = tuple(main)\n",
    "        #print(dataframe[\"reviews\"])\n",
    "        list_dataframes.append(dataframe)\n",
    "\n",
    "    currentpage += 1\n",
    "else:\n",
    "    currentpage = 1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame(list_dataframes,columns=list_dataframes[0].keys())\n",
    "df.to_csv(\"DataFiles/zomato_extracted_data_csv/zomato_extracted_data5May\"+\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
